{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AcousticBrainz Genre Task 2017: Content-based music genre recognition from multiple sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice graphs for high dpi screens\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn[alldeps]\n",
    "!pip install -U python-dotenv\n",
    "!pip install -U pandas\n",
    "!pip install nbstripout\n",
    "!pip install nbformat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You **must** restart the kernel after first instaling or updating packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utilities.ipynb\n",
    "%run Evaluation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load groundtruth and filter available records\n",
    "During development it is very likely the notebook is executed with a subset of the training data, because the training data is very large (approx 80 GiB). Therefore it is needed to filter out any records we don't want to use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read tsv file into groundtruth and extract only id and main genre from it\n",
    "groundtruth = load_groundtruth(settings['path'] + 'groundtruth/acousticbrainz-mediaeval2017-tagtraum-train.tsv')\n",
    "\n",
    "print 'Groundtruth size: %d' % len(groundtruth)\n",
    "print 'Found {} unique genres.'.format(len(groundtruth['genre1'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only run for manual sampling method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create better balanced training data\n",
    "By using a fixed number of recordings of each genre for training, the classifier will be better balanced. And this will hopefully remove bias to a genre that is in the dataset many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "single_genre = groundtruth[groundtruth['genre2'].isnull()]\n",
    "count_per_genre = single_genre[['genre1', 'main_genres']].groupby(['genre1']).count()\n",
    "sample_size = count_per_genre['main_genres'].quantile(0.5)\n",
    "\n",
    "balanced_groundtruth = pd.DataFrame()\n",
    "\n",
    "for genre, count in count_per_genre.iterrows():\n",
    "    specific_genre_groundtruth = single_genre[single_genre['genre1'] == genre]\n",
    "    \n",
    "    if count[0] > sample_size:\n",
    "        specific_genre_groundtruth = specific_genre_groundtruth.sample(n=int(sample_size))\n",
    "        \n",
    "    balanced_groundtruth = balanced_groundtruth.append(specific_genre_groundtruth)\n",
    "\n",
    "# Shuffle balanced_groundtruth\n",
    "balanced_groundtruth = balanced_groundtruth.sample(frac=1)\n",
    "# Load training data\n",
    "balanced_training_data = balanced_groundtruth['recordingmbid'].apply(getOnlyUsedFeatures)\n",
    "\n",
    "print 'Groundtruth size: %d' % len(balanced_groundtruth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_groundtruth[['genre1', 'main_genres']] \\\n",
    "    .groupby(['genre1']) \\\n",
    "    .count() \\\n",
    "    .plot.bar()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_genres = set(groundtruth['genre1'])\n",
    "new_groundtruth = pd.DataFrame()\n",
    "\n",
    "for genre in unique_genres:\n",
    "    sampling_groundtruth = groundtruth.loc[groundtruth['genre1'] == genre]\n",
    "    if (len(sampling_groundtruth) < 300):\n",
    "        sampling_groundtruth = sampling_groundtruth     \n",
    "    else:\n",
    "        sampling_groundtruth = sampling_groundtruth.sample(n=300)\n",
    "    \n",
    "    new_groundtruth = new_groundtruth.append(sampling_groundtruth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_groundtruth\n",
    "print len(new_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Maybe during development you want a really really small dataset ?\n",
    "if settings['very_few'] == 'True':\n",
    "    print 'Limit groundtruth to 10000 elements'\n",
    "    groundtruth = groundtruth.head(1000)\n",
    "    new_groundtruth = new_groundtruth[0:1000]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "training_data = groundtruth['recordingmbid'].apply(getOnlyUsedFeatures)\n",
    "\n",
    "print training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "def do_experiment(classifier, data, labels):\n",
    "    separation = int(len(data) * 0.9)\n",
    "    \n",
    "    training_data = data[0:separation]\n",
    "    training_labels = labels[0:separation]\n",
    "    \n",
    "    test_data = data[separation:]\n",
    "    test_labels = labels[separation:]\n",
    "    \n",
    "    return do_experiment_separate_training_data(classifier, \n",
    "                                                training_data, training_labels, \n",
    "                                                test_data, test_labels)\n",
    "\n",
    "def do_experiment_separate_training_data(classifier, training_data, training_labels, test_data, test_labels):\n",
    "    \n",
    "    classifier.fit(training_data, training_labels)\n",
    "\n",
    "    predictions = classifier.predict(test_data)    \n",
    "    test_truth = test_labels.apply(lambda x: [x])\n",
    "    \n",
    "    evaluation_results = evaluate(predictions, test_truth)\n",
    "\n",
    "    display(evaluation_results[0])\n",
    "    display(evaluation_results[1])\n",
    "    \n",
    "    return evaluation_results, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run Evaluation.ipynb\n",
    "\n",
    "clf = OneVsRestClassifier(svm.SVC(kernel='rbf', class_weight='balanced'))\n",
    "\n",
    "results_OvsR_SVC = do_experiment(clf, \n",
    "                                 balanced_training_data, \n",
    "                                 balanced_groundtruth['genre1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model_GaussianNB = GaussianNB()\n",
    "\n",
    "results_GaussianNB = do_experiment(model_GaussianNB, \n",
    "                                   balanced_training_data, \n",
    "                                   balanced_groundtruth['genre1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Undersampling using imbalance dataset library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, neighbors\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 50\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, groundtruth['genre1'],\n",
    "                                                     random_state=RANDOM_STATE)\n",
    "\n",
    "# Create a pipeline\n",
    "# pipeline = make_pipeline(NearMiss(version=2, random_state=RANDOM_STATE),\n",
    "#                          LinearSVC(random_state=RANDOM_STATE))\n",
    "pipeline = make_pipeline(SMOTE(random_state=RANDOM_STATE), neighbors.KNeighborsClassifier(3))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "print(classification_report_imbalanced(groundtruth['genre1'][-5000:], pipeline.predict(training_data[-5000:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_value = pipeline.predict(test_features)\n",
    "predict_value = pd.DataFrame(predict_value)\n",
    "predict_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " pettyPrintJSON(loadFeatures('1a00a335-fead-46ec-8d4f-06e8341291ea'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Using Manual Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(svm.SVC(kernel='rbf', class_weight='balanced'))\n",
    "clf.fit(training_data, new_groundtruth['genre1'])\n",
    "\n",
    "results = do_experiment(clf, training_data, new_groundtruth['genre1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmsr",
   "language": "python",
   "name": "mmsr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
