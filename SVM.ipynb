{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AcousticBrainz Genre Task 2017: Content-based music genre recognition from multiple sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice graphs for high dpi screens\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn[alldeps]\n",
    "!pip install -U python-dotenv\n",
    "!pip install -U pandas\n",
    "!pip install nbstripout\n",
    "!pip install nbformat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You **must** restart the kernel after first instaling or updating packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utilities.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load groundtruth and filter available records\n",
    "During development it is very likely the notebook is executed with a subset of the training data, because the training data is very large (approx 80 GiB). Therefore it is needed to filter out any records we don't want to use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read tsv file into groundtruth and extract only id and main genre from it\n",
    "groundtruth = load_groundtruth(settings['path'] + 'groundtruth/acousticbrainz-mediaeval2017-tagtraum-train.tsv')\n",
    "\n",
    "print 'Groundtruth size: %d' % len(groundtruth)\n",
    "print 'Found {} uniquse genres.'.format(len(groundtruth['genre1'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only run for manual sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_genres = set(groundtruth['genre1'])\n",
    "new_groundtruth = pd.DataFrame()\n",
    "\n",
    "for genre in unique_genres:\n",
    "    sampling_groundtruth = groundtruth.loc[groundtruth['genre1'] == genre]\n",
    "    if (len(sampling_groundtruth) < 300):\n",
    "        sampling_groundtruth = sampling_groundtruth     \n",
    "    else:\n",
    "        sampling_groundtruth = sampling_groundtruth.sample(n=300)\n",
    "    \n",
    "    new_groundtruth = new_groundtruth.append(sampling_groundtruth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_groundtruth\n",
    "print len(new_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Maybe during development you want a really really small dataset ?\n",
    "if settings['very_few'] == 'True':\n",
    "    print 'Limit groundtruth to 10000 elements'\n",
    "    groundtruth = groundtruth.head(10000)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "genre = Counter(groundtruth.genre1).keys() # equals to list(set(words))\n",
    "counter = Counter(groundtruth.genre1).values() # counts the elements' frequency\n",
    "\n",
    "df = pd.DataFrame(genre)\n",
    "df_2 = pd.DataFrame(counter)\n",
    "df_new = pd.concat([df, df_2], axis=1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "groundtruth.genre1.value_counts().plot(kind='bar')\n",
    "plt.show()\n",
    " #show power distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = groundtruth['recordingmbid'].apply(getOnlyUsedFeatures)\n",
    "\n",
    "print training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### See distribution of average loudness of each genre music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myset = set(groundtruth['genre1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "\n",
    "hist_loudness = np.arange(10)\n",
    "j=0\n",
    "\n",
    "for i in myset:    \n",
    "    groundtruth_genre = groundtruth[groundtruth['genre1'] == i]\n",
    "    training_data_genre = groundtruth_genre['recordingmbid'].apply(getOnlyUsedFeatures)\n",
    "    print i\n",
    "    loud = plt.hist(training_data_genre[13])\n",
    "    print np.shape(loud[0])\n",
    "    hist_loudness = np.vstack((hist_loudness, loud[0]))\n",
    "    j = j+1\n",
    "    plt.hist(training_data_genre[13])\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See distribution of spectral energy mean of each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "\n",
    "hist_energy = np.arange(10)\n",
    "j=0\n",
    "\n",
    "for i in myset:    \n",
    "    groundtruth_genre = groundtruth[groundtruth['genre1'] == i]\n",
    "    training_data_genre = groundtruth_genre['recordingmbid'].apply(getOnlyUsedFeatures)\n",
    "    print i\n",
    "    energy = plt.hist(training_data_genre[14])\n",
    "    print np.shape(loud[0])\n",
    "    hist_energy = np.vstack((hist_energy, energy[0]))\n",
    "    j = j+1\n",
    "    plt.hist(training_data_genre[14])\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Value in Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_count = np.shape(hist_loudness)[0]\n",
    "\n",
    "np.amax(hist_loudness[14])\n",
    "\n",
    "for i in range(genre_count):\n",
    "    max_value = np.amax(hist_loudness[i])\n",
    "    array_length = np.shape(hist_loudness)[1]\n",
    "    for j in range(array_length):\n",
    "        hist_loudness[i,j] = hist_loudness[i,j]/max_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_loudness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograms_similarity(histogram0, histogram1):\n",
    "  hs_sim = histogram0.astype(np.float32) - histogram1.astype(np.float32)\n",
    "  sim = 0\n",
    "  for i in range(0, hs_sim.size):\n",
    "    if(hs_sim[i] < 0):\n",
    "      sim = sim + histogram0[i]\n",
    "    else:\n",
    "      sim = sim + histogram1[i]\n",
    "     \n",
    "  return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example.\n",
    "print '1 vs 2: %.6f' % histograms_similarity(\n",
    "    hist_loudness[0, :],\n",
    "    hist_loudness[5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_self_similarity(feature_vector_matrix, similarity_function = histograms_similarity):\n",
    "  matsize = np.shape(feature_vector_matrix)[0]\n",
    "  sim_matrix = np.zeros((matsize, matsize))\n",
    "  for i in range(0, matsize):\n",
    "    for j in range(0, matsize):\n",
    "        sim_matrix[i, j] = similarity_function(feature_vector_matrix[i,:], feature_vector_matrix[j,:])\n",
    "  return sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms_self_similarity = compute_self_similarity(\n",
    "    hist_loudness, histograms_similarity)\n",
    "print 'HS histograms self-similarity matrix size: %d x %d' % np.shape(histograms_self_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(histograms_self_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(histograms_self_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dissimilarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograms_dissimilarity(histogram0, histogram1):\n",
    "  hs_dsim = abs(histogram0.astype(np.float32) - histogram1.astype(np.float32))\n",
    "  dsim = 0\n",
    "  for i in range(hs_dsim.size):\n",
    "    dsim = dsim + hs_dsim[i]\n",
    "     \n",
    "  return dsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms_dissimilarity(hist_loudness[0, :], hist_loudness[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example.\n",
    "print '1 vs 2: %.2f' % histograms_dissimilarity(\n",
    "    hist_loudness[0, :],\n",
    "    hist_loudness[5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_self_dissimilarity(feature_vector_matrix, dissimilarity_function = histograms_dissimilarity):\n",
    "  matsize = np.shape(feature_vector_matrix)[0]\n",
    "  dsim_matrix = np.zeros((matsize, matsize))\n",
    "  for i in range(0, matsize):\n",
    "    for j in range(0, matsize):\n",
    "        dsim_matrix[i, j] = dissimilarity_function(feature_vector_matrix[i,:], feature_vector_matrix[j,:])\n",
    "  return dsim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms_self_dissimilarity = compute_self_dissimilarity(\n",
    "    hist_loudness, histograms_dissimilarity)\n",
    "print 'HS histograms self-dissimilarity matrix size: %d x %d' % np.shape(histograms_self_dissimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(histograms_self_dissimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "myset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(svm.SVC(kernel='rbf', class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#clf = svm.SVC()\n",
    "clf.fit(training_data[0:1000], groundtruth['genre1'][0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_features = training_data[-100:]\n",
    "test_label = groundtruth['genre1'][-100:]\n",
    "print test_label\n",
    "print clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import Library of Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Train the model using the training sets \n",
    "model.fit(training_data[0:1000], groundtruth['genre1'][0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Predict Output \n",
    "predicted= model.predict(test_features)\n",
    "print predicted\n",
    "print test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Undersampling using imbalance dataset library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, neighbors\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 50\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, groundtruth['genre1'],\n",
    "                                                     random_state=RANDOM_STATE)\n",
    "\n",
    "# Create a pipeline\n",
    "# pipeline = make_pipeline(NearMiss(version=2, random_state=RANDOM_STATE),\n",
    "#                          LinearSVC(random_state=RANDOM_STATE))\n",
    "pipeline = make_pipeline(SMOTE(random_state=RANDOM_STATE), neighbors.KNeighborsClassifier(3))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "print(classification_report_imbalanced(groundtruth['genre1'][-5000:], pipeline.predict(training_data[-5000:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_value = pipeline.predict(test_features)\n",
    "predict_value = pd.DataFrame(predict_value)\n",
    "predict_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " pettyPrintJSON(loadFeatures('1a00a335-fead-46ec-8d4f-06e8341291ea'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Using Manual Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(svm.SVC(kernel='rbf', class_weight='balanced'))\n",
    "#clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Utility for sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "genre = Counter(new_groundtruth.genre1).keys() # equals to list(set(words))\n",
    "counter = Counter(new_groundtruth.genre1).values() # counts the elements' frequency\n",
    "\n",
    "df = pd.DataFrame(genre)\n",
    "df_2 = pd.DataFrame(counter)\n",
    "df_new = pd.concat([df, df_2], axis=1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.fit(training_data, new_groundtruth['genre1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prepare test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_features = training_data[-1000:]\n",
    "test_label = new_groundtruth['genre1'][-1000:]\n",
    "\n",
    "test_result = []\n",
    "\n",
    "print type(test_features)\n",
    "print type(test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testing_set = groundtruth.sample(n=100)\n",
    "test_label = testing_set['genre1']\n",
    "test_features = testing_set['recordingmbid'].apply(getOnlyUsedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_label = test_label.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_value = clf.predict(test_features)\n",
    "predict_value = pd.DataFrame(predict_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print type(test_label)\n",
    "test_label = pd.DataFrame(test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_result = pd.DataFrame()\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_result = test_label\n",
    "print type(test_result)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_result[\"predict\"] = predict_value\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(100):\n",
    "    if test_result[\"genre1\"][i] == test_result[\"predict\"][i]:\n",
    "        test_result[\"checker\"][i] = 1\n",
    "    else:\n",
    "        test_result[\"checker\"][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_result[\"checker\"].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
