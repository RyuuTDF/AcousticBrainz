{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# AcousticBrainz Genre Task 2017: Content-based music genre recognition from multiple sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Nice graphs for high dpi screens\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn[alldeps]\n",
    "!pip install -U python-dotenv\n",
    "!pip install -U pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "settings = {\n",
    "    \"path\": environ.get(\"PATH_TO_DATASET\"),\n",
    "    \"loaded_data\": environ.get('LOADED_TRAINING_DATA'),\n",
    "    \n",
    "    \"very_few\": environ.get('VERY_FEW_RECORDS', False),  # Limit the dataset to very few records, useful during development\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You **must** restart the kernel after first instaling or updating packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utilities.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load groundtruth and filter available records\n",
    "During development it is very likely the notebook is executed with a subset of the training data, because the training data is very large (approx 80 GiB). Therefore it is needed to filter out any records we don't want to use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read tsv file into groundtruth and extract only id and main genre from it\n",
    "groundtruth = load_groundtruth(settings['path'] + 'groundtruth/acousticbrainz-mediaeval2017-tagtraum-train.tsv')\n",
    "\n",
    "print 'Groundtruth size: %d' % len(groundtruth)\n",
    "print 'Found {} uniquse genres.'.format(len(groundtruth['genre1'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Maybe during development you want a really really small dataset ?\n",
    "if settings['very_few']:\n",
    "    print 'Limit groundtruth to 10000 elements'\n",
    "    groundtruth = groundtruth.head(10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loadFeatures(recordingmbid):\n",
    "    '''Load raw feature file of a record into an object'''\n",
    "    feature_file_path = '{basepath}acousticbrainz-mediaeval-train/{id_prefix}/{id}.json'.format(\n",
    "        basepath = settings['path'], id_prefix=recordingmbid[0:2], id = recordingmbid);\n",
    "    \n",
    "    with open(feature_file_path) as feature_file:    \n",
    "        data = json.load(feature_file)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def pettyPrintJSON(object_to_print):\n",
    "    print(json.dumps(object_to_print, sort_keys=True, indent=4))\n",
    "    \n",
    "\n",
    "def getOnlyUsedFeatures(recordingmbid):\n",
    "    '''Extract used functions from the raw feature file'''\n",
    "    all_features = loadFeatures(recordingmbid)\n",
    "    \n",
    "    used_features = [\n",
    "        'lowlevel.mfcc.mean'\n",
    "    ]\n",
    "    \n",
    "    result_features = []\n",
    "    \n",
    "    for feature_name in used_features:\n",
    "        reduced_features = all_features\n",
    "\n",
    "        for k in feature_name.split('.'):\n",
    "            reduced_features = reduced_features[k]\n",
    "        \n",
    "        result_features.extend(reduced_features)\n",
    "        \n",
    "    return pd.Series(result_features)\n",
    "    \n",
    "\n",
    "training_data = groundtruth['recordingmbid'].apply(getOnlyUsedFeatures)\n",
    "\n",
    "print training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform multi labels into matrix\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_matrix = mlb.fit_transform(groundtruth['main_genres'])\n",
    "print list(mlb.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(training_data[0:-1000], groundtruth['genre1'][0:-1000])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_data = training_data[-1000:]\n",
    "test = pd.DataFrame()\n",
    "test['truth'] = groundtruth['genre1'][-1000:]\n",
    "test['prediction'] = clf.predict(test_data)\n",
    "\n",
    "\n",
    "# Should be replaced with:\n",
    "# correct_prediction = verify_predictions(test['truth'], test['prediction'])\n",
    "correct_prediction = test['truth'] == test['prediction']\n",
    "\n",
    "\n",
    "# Should be replaced by evaluate function\n",
    "total = len(correct_prediction)\n",
    "correct = len(correct_prediction[correct_prediction == True])\n",
    "\n",
    "print 'Total: %d' % total\n",
    "print 'Correct: %d' % correct\n",
    "print 'Correct %% %.2f' % (100.0 * correct / total)\n",
    "\n",
    "\n",
    "print test.head()\n",
    "print correct_prediction.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmsr",
   "language": "python",
   "name": "mmsr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
